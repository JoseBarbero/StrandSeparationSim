{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import autokeras as ak\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, LayerNormalization\n",
    "from ReadData import read_data_as_img, read_data_structured, read_data_st\n",
    "from Preprocessing import ros, smote, adasyn\n",
    "from Results import report_results_imagedata, make_spider_by_temp, report_results_st, test_results, plot_train_history\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras import Sequential\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, log_loss, fowlkes_mallows_score, cohen_kappa_score, precision_score, recall_score\n",
    "from datetime import datetime\n",
    "from contextlib import redirect_stdout\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "X_train, y_train = read_data_st(data_dir, \"train\")\n",
    "X_val, y_val = read_data_st(data_dir, \"val\")\n",
    "X_test, y_test = read_data_st(data_dir, \"test\")\n",
    "\n",
    "#X_train = np.concatenate((X_train, X_val))\n",
    "#y_train = np.concatenate((y_train, y_val))\n",
    "#X_train, y_train = smote(X_train, y_train)\n",
    "X_train = X_train.reshape(*X_train.shape[:3], 1)\n",
    "X_test = X_test.reshape(*X_test.shape[:3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widenet():\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(11,200,1)))\n",
    "    model.add(MaxPooling2D((1, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=keras.losses.BinaryCrossentropy(), metrics=[\"accuracy\", \"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 9, 198, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 9, 99, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 9, 99, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 7, 97, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 3, 48, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 48, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 1, 46, 32)         9248      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1, 46, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1472)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               377088    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 396,161\n",
      "Trainable params: 396,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/trainHistoryDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-a1d8cee42d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             validation_split=0.2)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/trainHistoryDict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/trainHistoryDict'"
     ]
    }
   ],
   "source": [
    "model = widenet()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "            shuffle=True,\n",
    "            batch_size=32,\n",
    "            epochs=3,\n",
    "            verbose=False,\n",
    "            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(19, 20):\n",
    "    objects = []\n",
    "    with (open(\"logs/\"+str(i)+\".pkl\", \"rb\")) as openfile:\n",
    "        while True:\n",
    "            try:\n",
    "                objects.append(pickle.load(openfile))\n",
    "            except EOFError:\n",
    "                break\n",
    "    history = objects[0]\n",
    "    plot_train_history(history, \"logs/\"+str(i)+\"_01.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm logs/*_01.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, imgname):    \n",
    "    \n",
    "    fig, axs = plt.subplots(3)\n",
    "    \n",
    "    fig.set_size_inches(15, 20)\n",
    "    \n",
    "    fig.suptitle('Model train history', fontsize=22)\n",
    "    \n",
    "    axs[0].plot(history['accuracy'])\n",
    "    axs[0].plot(history['val_accuracy'])\n",
    "    axs[0].set_title('model accuracy')\n",
    "    axs[0].set(xlabel='epoch', ylabel='accuracy')\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    \n",
    "    axs[1].plot(history['loss'])\n",
    "    axs[1].plot(history['val_loss'])\n",
    "    axs[1].set_title('model loss')\n",
    "    axs[1].set(xlabel='epoch', ylabel='loss')\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    \n",
    "    axs[2].plot(history['auc'])\n",
    "    axs[2].plot(history['val_auc'])\n",
    "    axs[2].set_title('model auc')\n",
    "    axs[2].set(xlabel='epoch', ylabel='auc')\n",
    "    axs[2].legend(['train', 'val'], loc='best')\n",
    "    \n",
    "    fig.savefig(imgname)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "\tAccuracy score:  0.9146044254302979\n",
      "\n",
      "\tBinary crossentropy : 0.22706757485866547\n",
      "\n",
      "\tAUC ROC: 0.8635118007659912\n",
      "Test metrics:\n",
      "\tAccuracy score:  0.9070324897766113\n",
      "\n",
      "\tBinary crossentropy : 0.23398719727993011\n",
      "\n",
      "\tAUC ROC: 0.8641296625137329\n"
     ]
    }
   ],
   "source": [
    "print(\"Train metrics:\")\n",
    "test_results(X_train, y_train, model)\n",
    "print(\"Test metrics:\")\n",
    "test_results(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
